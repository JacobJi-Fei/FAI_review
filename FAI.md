# FAI

## Basic AI

### AI

- Definition (What is AI)

	- Artificial Intelligence (AI) is the branch of computer science that develops machines and software with intelligence
	- ä¸»è¦çš„ researchers å’Œ textbooks å®šä¹‰è¿™ä¸ªé¢†åŸŸä¸º the study of design of intelligent agents
where an intelligent agent is a system that perceives its environment and takes actions that maximize its chances of success.

- History of AI

	- 1943 WW2

		- Turing Test å›¾çµæµ‹è¯•
		- Influenced AI , till now

	- 1956 Birth of AI

		- John McCarthy and Marvin Minsky
		- AI term coined, Dartmouth University
		- Top down approach: pre-processed to do things
		- Bottom up approach: simulate brains, learn new behaviours

	- 1970's AI winter

		- Common sense reasoning and supposedly simple tasks like face recognition would always be beyond their capability

			- Reason

				- Funding for the industry was slashed èµ„é‡‘ä¸è¶³
				- Perceptron not able to implement basic function. æ„ŸçŸ¥å™¨ä¸èƒ½å®ç°åŸºæœ¬åŠŸèƒ½
				- Exampleï¼šMachine translations æœºç¿» å¿ƒæœ‰ä½™è€ŒåŠ›ä¸è¶³ 1950â€˜s

	- 1980 expert system, new hope

		- General problem solving vs. expert system

	- 1990 Bottom up approach

		- Immitate biology ,ANN

	- 1997 AI Game, Milestone

		- Deep Blue

	- 2002 First robot for the home

		- Roomba by iRobot

	- 2008 Speech recognition

		- Google

	- 2011

		- Watson won US quiz show Jeopardy

	- 2014 Turing test passed

- Turing Test

	- The test is conducted with two people and a machine ä¸¤ä¸ªäººä¸€ä¸ªæœºå™¨
	- One person plays the role of an interrogator and is in a separate room from the machine and the other person å…¶ä¸­ä¸€ä¸ªäººä½œä¸ºå®¡é—®è€…ï¼Œå’Œå…¶ä»–çš„æœºå™¨å’Œäººåˆ†éš”å¼€

		- The interrogator cannot see the machine and person, he only knows the person and machine as A and B. è¿™äººçœ‹ä¸è§æœºå™¨å’Œäººï¼Œ åªçŸ¥é“æœºå™¨å’Œäººæ˜¯Aæˆ–è€…Bï¼ˆå°¼ç›è¿™ä¸æ˜¯æ´¾è¥¿ç»´å°”ï¼‰
		- The interrogatorâ€™s task: to find out which candidate is the machine or human, only by asking them questions. 
å®¡é—®è€…çš„ä»»åŠ¡æ˜¯é€šè¿‡é—®é—®é¢˜æ‰¾å‡ºå“ªä¸ªæ˜¯äººå“ªä¸ªæ˜¯æœºå™¨

	- The aim of the machine is to fool the interrogator into thinking that it is a person. æœºå™¨çš„ç›®çš„æ˜¯æ··æ·†å®¡é—®è€…ï¼Œè®©ä»–è§‰å¾—è‡ªå·±æ˜¯äººï¼ˆå°è«ï¼Ÿï¼‰

		- If the machine can fool the interrogator 30% of the time, the machine is considered intelligent.

	- Suggested as a way of saying when we could consider machines to be intelligent, or at least act intelligently
	- A satisfactory operational definition of intelligence
	- The first machine to pass a Turing test

		- the chatbot "Eugene Goostman"

	- The need?

		- Natural language processing
		- Knowledge representation
		- Automated reasoning

			- to use the stored information to answer questions and to draw new conclusions. cå‚¨å­˜ä¿¡æ¯ç”¨æ¥å›ç­”å¹¶ä¸”æ€»ç»“å‡ºæ–°çš„ç»“è®º

		- Machine learning
		- Vision ( for Total Turing Test)
		- Motor control (total test)

			- to act upon objects as requested.æŒ‰è¦æ±‚å¯¹ç‰©ä½“æ–½åŠ ä½œç”¨

		- Other senses (total test)

			- such as audition, smell, touch, etc

- The Chinese Room

	- 1980 John Searle devised a thought experiment which he called the Chinese Room

		- Searle argued that the Turing test could not be used to determine if a machine can think
ä»–è®¤ä¸ºå›¾çµæµ‹è¯•ä¸èƒ½å†³å®šæœºå™¨å¯ä»¥æ€è€ƒ
		- Behaving intelligently was not enough to prove a computer was intelligent

	- comprise of

		- a human, who only understands English
		- a rule book, written in English
		- stack of paper

			- One stack of paper is blank
			- The other has symbols on them.

		- In computing terms

			- human - CPU
			- The rule book is the program
			- two stacks of paper are storage devices

	- the system does not understand Chinese as it just comprises a rule book and stacks of paper which do not understand Chinese.

		- åé©³å›¾çµæµ‹è¯•çš„ç‚¹

			- æœºå™¨èƒ½ç¿»è¯‘ä½†æ˜¯ä»–è¿˜æ˜¯ä¸æ‡‚ä¸­æ–‡
			- running the right program does not necessarily generate understanding, the system only act as it understands Chinese

### Strong AI vs. Weak AI

- John Searle
- Strong AI

	- A system can have a mind and mental states

- Weak AI

	- A system can act intelligently

		- there are non-intelligent ways to achieve intelligent tasks

### Basics in Machine learning

## Problem Formulation And Search Tree 

### basics

- Search space

	- Set of all possible solutions to a problem

- Search algorithms

	- Take a problem as input
	- Return a solution to the problem

### Definitions and examples of problems 

- Problem formulation

	- Problem formulation is the process of deciding what actions and states to consider, given a goal.
	- Problem components

		- Initial State

			- The starting state of the problem, defined in a suitable manner

		- Actions(operators)

			- An action or a set of actions that moves the problem from one state to another
			- The set of all possible states reachable from a given state s by applying all legal action is known as the neighbourhood and the action(s) can be recognized as the successor function

		- Goal Test

			- A test applied to a state which returns true if we have reached a state that solves the problem åˆ°æ²¡åˆ°ç»ˆç‚¹

		- Path Cost

			- How much it costs to take a particular sequence of actions è¿™ä¸€ç³»åˆ—actions çš„cost 

		- A solution to a problem is an action sequence that leads from the initial state to the goal state.

	- Example

		- Romania

			- Initial State

				- Arad

			- Operator

				- Driving between cities
				- State space consists of all 20 cities in the graph

			- Goal Test

				- Is the current state Bucharest?
				- a solution is a path from the initial to the goal state

			- Path cost

				- a function of time/distance/risk/petrol

		- 8-puzzle Game

			- Initial State

				- Specifies the location of each of the eight tiles and the blank in one of the nine squares

			- Operators

				- Blank tile moves left, right, up or down

			- Goal Test

				- The current state matches a certain state

			- Path Cost

				- Each move of the blank costs 1

			- How big is the State space

				- 9?

			- Number of actions/ operators
(how they are formulated)

				- 4 possible moves could be specified for each of the 8 tiles, 4 * 8 = 32
				- 4 moves for blank square - 4 operators

		- 8-Queen

- Problem representation

	- Trees - Terminology

		- Nodes

			- Root node
			- Children/parent of nodes
			- Leaves

		- Branches
		- Average branching factor

			- Average number of branches of the nodes in the tree

		- Depth

			- Depth of a node

				- the number of edges(branches) away from the root nodeè¯´ç™½äº†å°±æ˜¯åˆ°ç¬¬å‡ å±‚äº†
æ³¨æ„ï¼š root çš„ä½ç½® d = 0

			- Depth of a tree

				- The depth of a tree is the depth of the deepest node

		- Tree size

			- Nodes at d = 2çš„dæ¬¡æ–¹
			- Nodes in a tree = 2 çš„d+1 æ¬¡æ–¹  - 1

		- ä¸Problem components å¯¹åº”

			- States - nodes

				- Possible states of problem, defined in some suitable manner

			- Initial State - root node

				- The starting state of the problem

			- State Space â€“ all nodes in the tree

				- The set of all states reachable from the initial state

			- Neighborhood

				- The set of all possible states reachable from a given state
				- Branching factor: number of neighborhoods

			- Operators - branches

				- A set of actions that moves the problem from one state to another

	- Example

		- Romania
		- Tic-Tac-Toe

			- Nodes: states of problem
			- Root node: initial state of the problem
			- Branches: moves by operator
			- Branching factor: number of neighbours

	- Search Tree issues

		- Search trees grow very quickly
		- The size of the search tree is governed by the branching factor
		- Even the simple game with branching factor of 3 has a complete search tree of large number of potential nodes
		- The search tree for chess has a branching factor of about 35
		- Example

			- Claude Shannon delivered a paper in 1949 at a New York conference on how a computer could play chess.

				- Working at 200 million positions per second, Deep Blue would require 10100 years to evaluate all possible games.
				- 10çš„100æ¬¡æ–¹ is larger than the number of atoms in the universe.

### Good Solution

- How good is a solution

	- Does out search method actually find a solution?
	- good solution

		- Path cost
		- Search Cost

			- Time and Memory

	- Does it find the optimal solution? æœ€ä½³æ–¹æ¡ˆ

- Evaluation criteria

	- Strategies are evaluated along the following dimensions

		- Completeness

			- does it always find a solution if one exists

		- time complexity

			- number of nodes generated/expanded

		- space complexity

			- maximum number of nodes in memory

		- optimality

			- does it always find a least-cost solution

	- Time and space complexity are measured in terms of  

		- b

			- maximum branching factor of the search tree

		- d

			- depth of the least-cost solution

		- m

			- maximum depth of the state space

				- å¯èƒ½åˆ°âˆ

### Uninformed(blind) search algorithms

- No additional information about states beyond that provided in the problem definition
- Implementation

	- Fundamental actions(operators)
	- "Expand"

		- Ask a node for its children

	- "Test" 

		- Test a node to see whether it is a goal

- General Tree Search

	- frontier - ä¸€å±‚ä¸€å±‚å–

- Breadth First Search (BFS)

	- Method

		- Queuing function: adds nodes to the end of the queue(FIFO)

	- Implementation

		- Frontier nodes(open nodes, leaves)

			- have been discovered
			- have not yet been processed

				- Children not yet explored; not yet tested if they are goal

		- Visited nodes( closed nodes)

			- have been discovered
			- have been processed

				- Children explored; tested if they match a goal

		- Undiscovered nodes

			- have not yet been discovered

	- Evaluating a search

		- Completeness

			- Guaranteed to find a solution if one exist?

				- yes

		- Time Complexity

			- How long does it tale to find a solution?

				- bçš„dæ¬¡æ–¹

		- Space Complexity

			- How much memory required to perform the search?

				- bçš„dæ¬¡æ–¹

		- Optimality

			- Find the optimal solution(one or all optimal solutions)?

				- yes

		- b: the maximum branching factor
d: is the depth of the search tree
		- Big O: notation in complexity theory

			- We use it to measure how the problem size affects the algorithmâ€™s computational resource (time or memory).

		- Combinatorial explosion: 

			- the number of problem solutions grows exponentially with its size

- Depth First Search(DFS)

	- Method

		- Expand Root Node First
		- Explore one branch before exploring another branch
		- Queuing function: adds  nodes to the front of the queue(LIFO)
		- ç®€è€Œè¨€ä¹‹ï¼ŒæŠŠå·¦è¾¹é‚£ä¸€æ”¯å…¨æ‰¾å®Œ å†æ‰¾å³è¾¹

	- Evaluation

		- b: a branching factor
m: maximum depth
		- Space complexity

			- DFS requires storage of O(bm) nodes ?

		- Time complexity

			- O(bçš„mæ¬¡æ–¹ï¼‰in the worst case

		- Completeness

			- An infinite branch: never terminate = > no goal state exist in that branch

				- NO

		- Optimality

			- Finds a solution: is there a better solution at a lower level

				- NO

- Uniform cost search ( UCS)

	- UCS vs. BFS

		- Optimal condition

			- BFS: Cost: same for all branches
			- UCS: Cost never decreases

		- Order of nodes explored

			- BFS: Shallower noes first
			- UCS: Lowest cost node first

	- Cost: total cost of the path from the root to node n
	-  UCS(problem) returns a solution or failure
	- Evaluation

		- Optimality

			- BFS: Only if the branch costs are the same
			- UCS: Even branch costs are different

		- Completeness

			- Systematically search the whole tree ( in the worst case)

		- Time complexity

			- bçš„dæ¬¡æ–¹

		- Space complexity

			- bçš„dæ¬¡æ–¹

		- When UCS = BFS

			- When all branches have the same cost
			- We are talking about the worst case scenario

		- UCS is usually better than BFS

- Blind (Uniformed) Searches

	- Simply searches the State Space

		- No preference as to which node to expand next å¯¹ä¸‹ä¸€æ­¥çš„æ‰©å±•æ²¡æœ‰ä¼˜å…ˆçº§

	- The different blind searches

		- Characterised by searches

			- Characterised by | the order | which expands the nodes

				- Different node ordering: shape of the frontier
				- Different shapes of the frontier: very different memory usages

	- An uninformed search

		- Has no knowledge about its domain

### Blind Search vs. Heuristic Search

- Blind Search

	- Blindly choose where to search in the search tree (çJBæ‰¾ï¼‰

		- When problems get large, not practical any mpre

- Heuristic Search

	- Explore the node:  more likely to lead to the goal state
	- Using knowledge, so called informed search
	- Greedy search, A* search

### Informed search algorithmsï¼ˆHeuristic Search)

- Introduction

	- Add domain-specific information to select the best path along which to continue searching 
æ·»åŠ ç‰¹å®šé¢†åŸŸä¿¡æ¯æ¥é€‰æ¥ä¸‹æ¥èµ°å“ªä¸ª

		- !!!Work by deciding which is the next best code to expand to reach the goal using domain knowledge

	- Sometimes known as informed search, it is usually more efficient than blind searches
	- Heuristic Search works by deciding which is the next best node to expand 
Heuristic Search è¿è¡Œé€šè¿‡å†³å®šå“ªä¸€ä¸ªæ˜¯æœ€å¥½çš„ä¸‹ä¸€æ­¥ï¼Œ ä½†æ˜¯ä¸èƒ½ä¿è¯ä»–é€‰çš„ç¡®å®å°±æ˜¯æœ€å¥½çš„
	- A heuristic method is particularly used to rapidly come to a solution that is hoped to be close to the best possible answer, or 'optimal solutionâ€™ å¿«é€Ÿäº§å‡º-å¾—åˆ°æœ€å¥½çš„ç­”æ¡ˆ
	- Heuristic function h(n) estimates the "goodness" of a node n.

h(n) = estimated cost (or distance) of minimal cost path form n to a goal state
h(n) å°±æ˜¯ä¸€ä¸ªå‡½æ•°ç”¨æ¥ä¼°è®¡ä»nåˆ°ç»ˆç‚¹æœ€å°cost path çš„ cost æˆ–è€… distance.
	- All domain knowledge used in the search is encoded in h(n), which is computable from the current state description.
Domain knowledge å°±æ˜¯ç”¨åœ¨ h(n)ä¸­
	- In general, h(n) â‰¥ 0 for all nodes n and h(n) = 0 implies that n is a goal node

- Greedy Search

	- Use as an evaluation function f(n) = h(n) , sorting nodes by increasing values of f
	- Selects node to expand believed to be closest ("greedy") to a goal node 
	- It is only concerned with short term gains
	- It is possible to get stuck in an infinite loop unless mechanism for avoiding repeated states is in place
	- Not Complete
	- Not Optimal
	- Time complexity is O(bçš„dæ¬¡æ–¹ï¼‰

		- where d is the depth of the search tree

	- Space complexity is O (b çš„ d æ¬¡æ–¹ï¼‰

		- where d is the depth of the search tree

- UCS vs. Greedy Search

	- Order of nodes to explore

		- UCS: Nodes of the lowest path cost
		- Greedy search: Nodes which are the closest to the goal

	- Cost(n)

		- UCS: g(n): actual path cost thus far
		- Greedy Search: h(n): estimate cost to the goal( using heuristic)

- A* Search

	- UCS is a special case of BFS which can be applied to graphs where the costs of each branch vary
	- UCS works by expanding the lowest cost node on the fringe é€šè¿‡è®¡ç®—æœ€ä½cost node
	- Combines the cost so far and the estimated cost to the goal ç»“åˆä»èµ·ç‚¹åˆ°ç°åœ¨çš„cost å’Œ ä¼°è®¡ä¹‹ååˆ°ç»ˆç‚¹çš„cost

		- f(n) = g(n) + h(n)

			- g: cost from the initial state to the current state
			- h: the cost from the current state to a goal state
			- f: an evaluation of the state: estimated cost of the cheapest solution through n
			- h = 0, A* becomes UCS

				- complete & optimal*, but search undirected

					- *when cost along path never decrease

			- h too large thus dominates g

				- becomes Greedy, lose optimality

	- Optimal and complete

		- If the heuristic is admissible

			- ï¼ï¼ï¼Admissible: the heuristic must never over estimate the cost to reach the goal

				- Â­h(n): a valid lower bound on cost to the goal

					- hn æ˜¯å®šä¸€ä¸‹ä¸‹ä¸€ä¸ªnode çš„æ–¹å‘ï¼Œå¿…é¡»æ˜¯h(n)é€æ¸å˜å°

	- Example

		- 8-puzzle-game

			-  develop an admissible heuristic in A* that does not over estimate, to find the optimal solution

				- h1 = no. of tiles in the wrong position
				- h2 = sum of the distance of the tiles to their goal positions using the Manhattan Distance
				- INFORMEDNESS

					- h2 is much more informed
					- Domination translate to efficiency: A* using h2 will never expand more nodes than A* using h1, h2 æ°¸è¿œä¸ä¼šæ¯”ä½¿ç”¨h1æ‰©å±•æ›´å¤šçš„èŠ‚ç‚¹
					- ä½¿ç”¨å…·æœ‰è¾ƒé«˜å€¼çš„å¯å‘å¼å‡½æ•°ï¼Œåªè¦å®ƒä¸é«˜ä¼°å¯å‘å¼çš„è®¡ç®—æ—¶é—´ä¸æ˜¯å¤ªå¤§

	- Effective branching factor

		- Effective branching factor: average no. of branches expanded
		- Quality of a heuristic:

			- average effective branching factor

		- A good heuristic

			- The closer the estimate of the heuristic, the better
			- Lower average effective branching factor
			- Admissible

		- é€‰é‚£ç§èƒ½å¾—åˆ°æœ€ä½³ç»“è®ºä¸”expand nodes å°‘çš„

## Game Playing (Adversarial Search)

### Components of Game Search

- The initial state

	- board position, indication of those move it is

- A set of operators

	- define the legal moves that a player can make

- A terminal test

	- determines when the game is over ( terminal states)

- A utility (payoff) funcition

	- gives a numeric value for the outcome(terminal state) of a class (like chess: +1, 0, 1/2)

### Minimax

- utility function (minimax value) of a node

	- the utility (for MAX) of being in the corresponding state ( larger values are better for "MAX")

- MAX: take the best move for MAX

	- Next state: the one with the highest utility

		- i.e. the maximum of its children in the search tree

- MIN: take the best move for MIN(the worst for MAX)

	- Next state: the one with the lowest utility 

		- i.e. the minimum of its children in the search tree

- ä¸¤ä¸ªç©å®¶ä¸€ä¸ª MIN ä¸€ä¸ª MAX ï¼Œ MAXèµ°çš„éƒ½æ˜¯è®©utility å¤§çš„ä¸€æ­¥ï¼Œ å°±æ˜¯è®©MAXèµ¢ï¼Œ MIN èµ°çš„å°±æ˜¯è®©utility å°çš„ä¸€æ­¥ï¼Œå°±æ˜¯ä¸è®©MAXèµ¢
- Example

	- Nim

		- utility function

			- 0 =  a win for MIN
			- 1 = a win for MAX

- Efficiency of the search

	- Game trees are very big
	- vEvaluation of positions is time-consuming

- How can we reduce the number of nodes to be evaluated??

	- alpha-beta pruning based on minimax, Deep Blue
	- Better estimation of utility values (possibility of winning), i.e. heuristic, ANN, etc.

### ALPHA-BETA PRUNING

- Pruning allow us to ignore portions of the search tree that make no difference to the final choice 
å¿½ç•¥é‚£äº›å¯¹final choice æ²¡æœ‰å½±å“çš„portions

	- Why useï¼Ÿ

		- The number of nodes grow exponentially, nodes çš„æ•°é‡ä»¥æŒ‡æ•°å½¢å¼å¢é•¿
		- It is possible to compute the correct minimax decision without looking at every node in the game tree ä¸éœ€è¦çœ‹æ ‘ä¸­çš„æ¯ä¸€ä¸ªèŠ‚ç‚¹å°±å¯ä»¥å¾—å‡ºç»“æœ
		- Use the idea of pruning to eliminate large parts of the tree from consideration

- alpha-beta pruning effection

	- If this is done well then alpha-beta search can effectively double the depth of search tree that is searchable in a given time. 
æ ‘å¯ä»¥æ›´æ·±

- Two parameters

	- alpha 

		- Î± values are stored with each MAX node
		- the highest-value we have found so far at any choice point along the path of MAX

	- beta

		- values are stored with each MIN node
		- the lowest-value we have found so far at any choice point along the path of MIN

- If we were doing BFS, would you still be able to prune nodes in this fashion?

	- NO! Because the pruning on node D is made by evaluating the tree underneath D
	- This form of pruning relies on doing a DFS

- To maximise pruning: first expand the best childrenæœ€å¤§ç¨‹åº¦åœ°pruning

	- cannot know which ones are really best
	- use heuristics for the â€œbest-firstâ€ ordering
	- Heuristic evaluation function allow us to approximate the true utility of a state without doing a complete search.
ç”¨ Heuristic evaluation function å»ä¼°è®¡ä¸€ä¸ªsate å»çœŸæ­£åˆ©ç”¨å½“è¿˜æ²¡åšå®Œä¸€ä¸ªcomplete search

### CLASSIFICATION

- Fully observable

	- Both players have full and perfect information about the current state of the game

- Partially observable

	- Players do not have access to the full â€œstate of the gameâ€

		-  card games â€“ you typically cannot see all of your opponents cards

- Deterministic

	- There is no element of chance
	- The outcome of making a sequence of moves is entirely determined by the sequence itself

- Stochastic

	-  there is some element of chance

		- E.g. Backgammon â€“ throw dice in order to move

### How is a game represented as a search problem?

- The different states of the game are represented by nodes in the game tree,

## Neural Network

### Artificial Neural Network

### Simulating, on a computer, what we understand about neural networks in the brainåœ¨è®¡ç®—æœºä¸Šæ¨¡æ‹Ÿæˆ‘ä»¬æ‰€äº†è§£çš„åœ¨å¤§è„‘ä¸­çš„è‡ªç„¶ç½‘ç»œ

### The first neural network

- 1943, McCulloch and Pitts
- Consists of

	- A set of inputs

		- dendrites æ ‘çª

	- A set of resistances/weights æƒé‡

		- synapses çªè§¦

	- A processing element

		- neuron ç¥ç»å…ƒ

	- A single output

		- axonè½´çª

### Three different classes of network architectures

- single-layer feed-forward
- multi-layer feed-forward
-  recurrent

### perceptronï¼ˆæ„ŸçŸ¥å™¨ï¼‰
single layer NN

- Linear Separability

	- Functions which can be separated in this way are called linearly separable
çº¿æ€§å¯åˆ†å‡½æ•°
	- Only linearly Separable functions can be represented by a single layer NN (perceptron)
åªæœ‰çº¿æ€§å¯åˆ†å‡½æ•°å¯ä»¥ç”¨å•å±‚NNè¡¨ç¤º

- Representation
- Limitations (linearly separable)
- Learning
- Threshold é˜ˆå€¼

## Machine Learning

### Machine Learning relates with the study, design and development of the algorithms that give computers the capability to learn without being explicitly programmed
-- Arthur Samuel

### Data

- Machine learningâ€’ computer learns from data, which represents â€œpast experiencesâ€ of an application domain
- Learn from examples

	- a machine learning algorithm then takes these examples and produces a program that does the job 

### Process

- Training set

	- Learning the parameters of the model

- Test set

	- How the results will generalize to an independent (novel) data set

### Supervised learning

- the agent observes some example input- output pairs and learns a function that maps from input to output

	- å°±æ˜¯æˆ‘ä»è¿™ä¸ªtrainning test learningä¹‹å æˆ‘ç»™ä¸€ä¸ªinput ä»–å°±èƒ½å¯¹åº”ç»™å‡ºç¡®å®šçš„ç»“æœ

- Classification

	- (output) y is discrete (class labels). Learn a decision boundary that separates one class from another

- Regression

	- y is continuous, e.g. linear regression. Learn a continuous input-output mapping,

- Example

	- è¯†åˆ«å‡ºå›¾åƒæ˜¯ï¼Œä»€ä¹ˆæ¯”å¦‚ğŸ± ğŸ¶ ğŸš— ğŸ 
	- ä¸€ä¸ªç”¨æˆ·ä¼šç»™å“ªå®¶é¤é¦†è¯„åˆ†å—
	- è¿™ä¸ªæ˜¯åƒåœ¾é‚®ä»¶å—
	- what will be the sales, stock price next year

### Unsupervised learning

- given only samples x of the data, infers a function f such that y = f(x) describes the hidden structure of the unlabeled data - more of an exploratory/descriptive data analysis

	- èƒ½æè¿°å‡ºæ¥æ²¡æœ‰æ ‡è®°çš„æ•°æ®ç»“æ„ï¼Œæ¢ç´¢æ–°çš„æ•°æ®åˆ†æ

- Clustering èšé›†ï¼Œåˆ†ç±»å½’ç±»

	- y is discrete. Learn any intrinsic structure that is present in the data. äº†è§£æ•°æ®ä¸­å­˜åœ¨ä»»ä½•çš„æ•°æ®ç»“æ„

- Dimensional Reduction æ•°æ®é™çº¬

	-  y is continuous. Discover a lower- dimensional surface on which the data lives å‘ç°æ•°æ®æ‰€åœ¨çš„ä½çº¬è¡¨é¢ï¼Ÿ

### ML Application

- CV

	- Image tagging
	- ï‚­ Self-driving car
	- ï‚­ Image pattern recognition

- Text Analysis

	- Spam filtering
	- ï‚­ Information extraction

- Video Games & Robotics

	- Checker/chess/go

- Data Mining æ•°æ®æŒ–æ˜

### Data Mining

- Introduction

	- the exploration and analysis of large quantities of data in order to discover valid, novel, potentially useful, and ultimately understandable patterns in data.

		- Valid: hod on new data with some certainty
		- Novel: non-obvious to the system
		- Useful: should be possible to act on the item
		- Understandableï¼š humans should be able to interpret the pattern

- purpose

	- explains patterns
	- predicts with models (Machine learning)

- Why data mining

	- Banking: loan/credit card approval
	- Fraud detection: network security, financial transactions

		- use historical data to build models of fraudulent behavior and use data mining to help identify similar instances

	- Customer relationship management
	- Medicine: disease outcome, effectiveness of treatments
	- Astronomy: scientific data analysis
	- Web site design and promotion:

- Tasks

	- Predictive

		- use some variables to predict unknown or future values of other variables

			- Classification

				- Identify to which set a new observation belongs

					- æ‰¾observation å±äºå“ªä¸€ä¸ªset

						- è¯´ç™½äº†ä¸€ä¸ªä¸œè¥¿æ‰”è¿›å¯¹åº”ç±»é‡Œ

	- Descriptive

		- Find human-interpretable patterns that describe the data

			- Clustering

				- Group a set of objects so objects in the same cluster are more similar

					- å°† ä¸€ç³»åˆ—objectsèšé›†åœ¨ä¸€èµ·ï¼Œä½¿å¾—è¿™ä¸€èšç±»çš„objects æ›´ç›¸ä¼¼

						- æŠŠä¸€å †ä¸œè¥¿åˆ†æˆå‡ å †ç›¸ä¼¼çš„æ”¾ä¸€å—

			- Association rule discovery

				- Discover interesting relations between variables in large databases

					- åœ¨ä¸€ä¸ªå¤§çš„æ•°æ®åº“é‡Œæ‰¾åˆ°å˜é‡é—´æœ‰æ„æ€çš„å…³ç³»

				- Identify rules using some measures

					- æ‰¾åˆ°è¿™ä¸ªå…³ç³»çš„è§„åˆ™

### Classification (Supervised learning)

- Learn a method to predict the instance class from pre-labeled( classified) instance
- Approaches

	- Regression
	- Decision Trees

		- Pros

			- Reasonable training time
			- Can handle large number of attributes
			- Easy to implement
			- Easy to interpret
			- è®­ç»ƒæ—¶é—´reasonableï¼Œ å¯ä»¥è§£å†³å¤§æ•°é‡çš„attributesï¼Œæ–¹ä¾¿å±•ç¤ºï¼Œæ–¹ä¾¿è¯´æ˜

		- Cons

			- Simple decision boundaries
			- Problems with lots of missing data
			- Cannot handle complicated relationship between
			- å†³ç­–è¾¹ç•Œç®€å•ï¼Œå¤§é‡æ•°æ®ç¼ºå¤±ä¼šå‡ºç°é—®é¢˜ï¼Œæ— æ³•å¤„ç†å¤æ‚çš„æ•°æ®å…³ç³»

	- Neural Networks

		- Pros

			- Can learn more complicated class boundaries
			- Can be more accurate
			- Can handle large number of features
			- å¯ä»¥å­¦ä¹ æ›´å¤æ‚çš„åˆ†ç±»è¾¹ç•Œï¼Œ å¯ä»¥æ›´å‡†ç¡®ï¼Œ å¯ä»¥è§£å†³å¤§æ•°é‡features çš„é—®é¢˜

		- Cons

			- Hard to implement: trial and error for choosing parameters 
			- Slow training time
			- Can over-fit the data : find patterns in random noise
			- Hard to interpret
			- å¾ˆéš¾å±•ç¤ºï¼Œå¾ˆæ…¢çš„è®­ç»ƒæ—¶é—´ï¼Œ å’Œæ•°æ®è¿‡åº¦æ‹Ÿåˆï¼Œå¾ˆéš¾å»è¯´æ˜

- Data

	- a collection of records

		- Each record contains a set of attributes
		- One of the attributes is the class attribute

- Goal

	- assign a class to unseen records correctly

- Process

	- Divide the given data set into training & test sets
	- Use training set to build the model
	- y test set to validate the model
	- å°†æ•°æ®é›†åˆ†å¼€ï¼Œè®­ç»ƒé›†ç”¨æ¥å¾—å‡ºæ¨¡å‹ï¼Œå°†è¿™ä¸ªæ¨¡å‹æ”¾åˆ°æµ‹è¯•é›†é‡Œæµ‹è¯•ä¸€ä¸‹

- Application

	- Target marketing

		- Goal: Reduce cost of mailing by targeting consumers who are likely to buy a new cell-phone product

- KNN ï¼ˆ K-Nearest neighbor)

	- One of the first choices for a classification study when there is little or no prior knowledge about the distribution of the data.

		- classification study é¦–é€‰

### Clustering ( unsupervised learning)

- Task

	- to partition the data so the instances are grouped in similar items by using distance/similarity measure

		- åˆ†åŒºæ•°æ®

- Introduction

	- A set of data points, each with a set of attributes and a similarity measure, find clusters such that
æ¯ä¸ªéƒ½æœ‰ä¸€ç»„å±æ€§å’Œç›¸ä¼¼æ€§åº¦é‡ï¼Œæ‰¾åˆ°è¿™æ ·çš„èšç±»

		- Data points in one cluster are more similar
		- Data points in separate clusters are less similar to one another

	- Key

		- Measure of similarity between instances

			- Euclidean or Manhattan distance

				- Euclidean: ä¸¤ç‚¹ä¹‹é—´è·ç¦»
				- Manhattanï¼š ä¸¤ç›´è§’è¾¹è·ç¦»å’Œ

			- Hamming distance
			- Other problem specific measures

- Method

	- Partitioning-based clustering

		- K-means clustering
		- ï‚­ K-medoids clustering

	- Density-based clustering
åŸºäºå¯†åº¦çš„èšç±»

		-  Separate regions of dense points by sparser regions of relatively low density

- K-Means

	- Goal

		- minimise sum of square of distance

			- Between each point and centers of the cluster.

				- ç‚¹åˆ°ä¸­å¿ƒç‚¹é—´

			- Between each pair of points in the cluster

				- æ¯ä¸€å¯¹ç‚¹é—´

- Density-based clustering

	-  A cluster: a connected dense component
	- Density: the number of neighbors of a point
	- Can find clusters of arbitrary shape
	- æŠŠdense component é“¾æ¥èµ·æ¥

- Application

	- Market Segmentation

		- Goal: divide a market into distinct subsets of customers, any subset may be a market target

			- å°†å¸‚åœºåˆ’åˆ†ä¸ºä¸åŒçš„å®¢æˆ·ç¾¤

		- Approach

			- Collect different attributes of customers, based on their related information (lifestyle, etc.)
			- Find clusters of similar customers
			- Evaluate buying patterns in the same cluster vs. those from different clusters

### Associate rules

- Associate Rule Discovery

	- discover interesting relations between variables in large databases
	- Shopping cart filled with several items

		- æ¯”å¦‚ä¸€ä¸ªäººä¹°äº†é¸¡è›‹ ä»–ä¸€å®šä¼šä¹°ç‰›å¥¶å—ï¼Œ æˆ–è€…è¯´ è¿™ä¸ªè´­ç‰©è½¦é‡Œä»–æœ‰ç‰›å¥¶çš„å¯èƒ½æ€§æ˜¯å¤šå°‘

	- Association rules

		- 60% of customers who purchase X and Y also buy Z

	- Sequential patterns
æ¬¡åºæ¨¡å¼

		- 40% of customers who first buy X also purchase Y within three weeks

			- æœ‰ä¸€å®šé¡ºåºæ€§

- Goal

	- identify items bought together by many customers

- Approach

	- Process data collected with barcode scanners  Find dependencies among items

- A classic rule

	- If a customer buys diaper & milk, then he is very likely to buy beer

## Probabilistic Reasoning and Bayes' Theorem

### Probability Theory

- Overview

	- Basic Concepts

		- A probability model is a mathematical representation, defined by its sample space S, events A within the sample space, and probabilities P(A)
		-  basic rules of probability 

			- Rule 1: Any probability P(A) is number between 0 and 1 (0 â‰¤ P(A) â‰¤ 1)
			-  Rule 2: The probability of the sample space S is always equal to 1 (P(S) = 1)
			- Rule 3: If two events A and B are disjoint, the probability of either event is the sum of probabilities of two events P(A or B) = P(A) + P(B)
			- Rule4:P(Ac)=1â€“P(A)
			- Rule 5: If two events are independent, then the probability of both events happening is the product of probabilities of each event: P(A and B) = P(A)P(B)
			- Rule6:P(AVB )=P(A)+P(B)â€“P(A^ğ‘©)

- Disjoint

	-  If two events have no outcome in common, they are called disjoint.

- Independence

	- Consider the coin flipping event, flip the coin two times, what the probability of getting â€œheadâ€s. The outcome of the 1st event (1st flip) has no effect on the probability of the 2nd event (2nd flip), then the two events are independent.

### THE JOINT PROBABILITY DISTRIBUTION

- Joint probabilities can be between any number of variables
- For each combination of variables, we can show how probable that combination is
- The probabilities of these combinations need to sum to 1

*XMind - Trial Version*